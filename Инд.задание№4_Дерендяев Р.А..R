ds4<-DS_4_8
any(is.na(ds4)==TRUE)
str(ds4)
names(ds4)
library(ggplot2)
library(lessR)
library(dplyr)
library(corrgram)
  
#1/Постройте множественную регрессию, выбрав в качестве объясняемой переменной количество тяжелых преступлений, 
#проинтерпретируйте полученные результаты 
model_1<-lm(data=ds4, Nпрест~.)
summary(model_1)
#модель является статистически не значимой: р=0,1765, критерий Фишера<Fкр=2,1
#Все кф регрессии (кроме фактора численности населения) являются статистически не значимы, кроме свободного члена.
#Использование модели не целесообразно


#2/Постройте множественную регрессию, выбрав в качестве объясняемой переменной количество тяжелых преступлений в расчете 
#на 1000 жителей, и включив в состав объясняющих переменных соотношение суммарных доходов 10 % самых богатых и самых бедных 
#жителей, а также плотность населения, проинтерпретируйте полученные результаты 
model_2<-lm(data=ds4, I(Nпрест/Население)~I(Доля_дохода_богатых/Доля_дохода_бедных)+I(Население/Sгорода))
summary(model_2)
y<-ds4$Nпрест/ds4$Население
x<-ds4$Доля_дохода_богатых/ds4$Доля_дохода_бедных
z<-ds4$Население/ds4$Sгорода
ds4_1<-as.data.frame(cbind(y,x,z))
Regression(data=ds4_1, y~x+z)
#плотность населения является статистически значимой величиной, с ее увеличением на 1 ед количество преступлений на 1000 жителей
#снижается на 0,12.Соотношение доходов 10% богатых и бедных жителей не является статистически значимой величиной, р=0,135
#При росте показателя на 1 ед. отклик снижается на 0,005 ед.В целом модель является статистически значимой F>Fкр и р<0,05
#кф детерминации 0,024.Применение модели считаю не целесообразным в виду низкой объясняемой доли дисперсии зависимой переменной


#3/Постройте множественную регрессию, выбрав в качестве объясняемой переменной количество тяжелых преступлений в расчете на 1000 
#жителей, и определив автоматически наиболее оптимальный состав факторов модели, проинтерпретируйте полученные результаты 
# Посмотрим на корреляционные поля числовых переменных

ggplot(ds4, aes(x=Безработица, y=I((Nпрест/Население))))+geom_point()+stat_smooth(method="lm") 
ggplot(ds4, aes(x=Средний_доход, y=I((Nпрест/Население))))+geom_point()+stat_smooth(method="lm")
ggplot(ds4, aes(x=Доля_дохода_богатых, y=I((Nпрест/Население))))+geom_point()+stat_smooth(method="lm")
ggplot(ds4, aes(x=Доля_дохода_бедных, y=I((Nпрест/Население))))+geom_point()+stat_smooth(method="lm")
ggplot(ds4, aes(x=Sгорода, y=I((Nпрест/Население))))+geom_point()+stat_smooth(method="lm")
ggplot(ds4, aes(x=Доля_мигрантов, y=I((Nпрест/Население))))+geom_point()+stat_smooth(method="lm") 
#По результатам построения по ряду зависимостей можно предположить наличие линейной завимости

      #метод №1
#install.packages('leaps')
library(leaps)
        
model_regsubset<-regsubsets(I(Nпрест/Население)~.,data=ds4,nbest=2,method="exhaustive")
#install.packages('HH')
library(HH)
summaryHH(model_regsubset)
plot(summaryHH(model_regsubset))
model_3_1<-lm(data=ds4, I(Nпрест/Население)~Sгорода)
summary(model_3_1) #модель статистически не значима: F=0.8464, p=0.3598, R2=0.008

      #метод №2
#install.packages('MASS')
library(MASS)
model_3_2<-lm(data=ds4, I(Nпрест/Население)~.)
model_step_wise<-stepAIC(model_3_2, direction = 'both')
summary(model_step_wise) #статистически значимых факторов не выявлено

      #метод №3
#install.packages('perty')
library(party)
cf1<-cforest(I(Nпрест/Население)~., data=ds4, control=cforest_unbiased(mtry=2,ntree=50))
varimp(cf1)
order(varimp(cf1))
model3_3<-lm(data=ds4,I(Nпрест/Население)~Доля_мигрантов+Sгорода+Безработица)
summary(model3_3) #модель статистически не значима: F=0.4742, p=0.7009, R2=0.014

      #метод №4
#install.packages('glmnet')
library(glmnet)
x3_4<-model.matrix(I(Nпрест/Население)~., data=ds4)
x3_4
x3_4=x3_4[,-1]
model_glmnet<-glmnet(x=x3_4, y=ds4$Nпрест/ds4$Население, type.measure='mse')
nams<-coef(model_glmnet, s=0.01)
row.names(nams)[order(nams, decreasing = TRUE)]
model3_4<-lm(data = ds4, I(Nпрест/Население)~Безработица+Доля_дохода_бедных+Доля_дохода_богатых)
summary(model3_4) #модель статистически не значима: F=0.4525, p=0.7161, R2=0.013

    #метод №5
#install.packages('relaimpo')
library(relaimpo)
lmMod<-lm(I(Nпрест/Население)~., data=ds4)
relImportance<-calc.relimp(lmMod, type = 'lmg', rela=T)
sort(relImportance$lmg, decreasing = T)
model3_5<-lm(data=ds4,I(Nпрест/Население)~Sгорода+Безработица+Доля_дохода_богатых)
summary(model3_5)#модель статистически не значима: F=0.6159, p=0.6063, R2=0.018

#По результатам автоматического построения регрессии 5 методами установлено, что все модели являются статистически не значимыми
#Для дальнейшего анализа будет использована регрессия, полученная методом №5 (сложная модель с наибольшм кф детерминации)




#4/Разделите исходную выборку на обучающую и контрольную в формате 70/30, обучите модель по данным обучающей выборки, 
#проверьте ошибку прогнозирования и изменение значимости модели. Повторите процедуру 5 раз, 
#проинтерпретируйте полученные результаты 
library(magrittr)
library(dplyr)
library(caret)

training.samples <- (ds4$Nпрест/ds4$Население) %>%
  createDataPartition(p = 0.7, list = FALSE) 
train.data <- ds4[training.samples, ] #тренировочная таблица
test.data <- ds4[-training.samples, ] #для тестирования
model3_5_tr<-lm(data=train.data,I(Nпрест/Население)~Sгорода+Безработица+Доля_дохода_богатых) #обучение модели
summary(model3_5_tr)
prediction_3_5<-predict(model3_5_tr,test.data[,-1,-2])# Предсказание по модели, убрав из таблицы первые два столбца
RMSE_3_5 = RMSE(prediction_3_5, test.data$Nпрест/test.data$Население) # Среднеквадратичная ошибка (RMSE)
MAE_3_5 = MAE(prediction_3_5, test.data$Nпрест/test.data$Население) # Средняя абсолютная ошибка (MAE)
cbind(RMSE_3_5, MAE_3_5)
#Повторял вышестоящий блок команд 5 раз

#результаты 5 процедур
#1 R2=0.033 F=0.800 p=0.498 RMSE=2.679 MAE=1.753
#2 R2=0.023 F=0.568 p=0.637 RMSE=2.903 MAE=1.728
#3 R2=0.021 F=0.516 p=0.673 RMSE=2.810 MAE=1.639
#4 R2=0.037 F=0.899 p=0.446 RMSE=2.027 MAE=1.522
#5 R2=0.036 F=0.877 p=0.457 RMSE=1.997 MAE=1.540
#на основании проведенных процедур модель в целом также остается статистически не значимой, относительная ошибка составляла по
#результатам 5 измерений от 1,9 до 2,9, средняя абсолютная ошибка - от 1,52 до 1,75. Данные ошибки являются достаточно большими
#и свидетельствуют о том, что модель в целом не целесообразно использовать для прогнозирования искомой величины.


#5/Постройте оптимально полученную в п.3 модель, применив метод контроля 10 раз по 3 блокам, 
#сделайте выводы об устойчивости коэффициентов модели
ds4<-cbind(ds4,ds4$Nпрест/ds4$Население)
colnames(ds4)[9]<-'PrestNas'

train.control <- trainControl(method = "repeatedcv",
                              number = 3, repeats = 10) # Разделим на 3 подмножества и повторим 10 раз
model_tr_repeat_3_5 <- train(PrestNas~Sгорода+Безработица+Доля_дохода_богатых, data = ds4, method = "lm",
                              trControl = train.control)
model_tr_repeat_3_5$results

#По результатам тестирования модель в целом является не достаточно устойчивой, о чем свидетельствуют высокие значения стартных 
#отклонений по каждому анализируемому параметру. Данный факт также свидетельствует о том, что полученную модель не целесообразно
#использовать для прогноза и является статистически не пригодной.
